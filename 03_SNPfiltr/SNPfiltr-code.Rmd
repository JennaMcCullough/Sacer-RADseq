---
title: "Todiramphus sacer SNPFiltR"
author: "Jenna McCullough"
date: "12 October 2023"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## libraries
```{r}
#install.packages("SNPfiltR");data(vcfR.example)
library(SNPfiltR)
library(tinytex)
library(vcfR)
library(ggplot2)
```

## Reading in the data
I am only showing code for the full dataset. Please see table S2 for the specific stats 
to produce the subsetted datasets.

This code is nearly verbatim from Devon DeRaad's tutorial for SNPFiltr. 
Please look at it--there's much more information there 
https://github.com/DevonDeRaad/SNPfiltR
 
At the bottom of this file is instructions to get a whitelist of loci for 
phylogenetic analyses 
 
```{r}
# set your working directory
# setwd("~/Dropbox/Publications/2022-McCullough-sacer-gbs/sacer-GBS/analyses/03_final-dataset")
# I put the vcf file from #2 in a folder called "CARC_output"

vcfR <- read.vcfR("CARC-output/sacer63_50per.vcf")
### check the metadata present in your vcf
vcfR

### read in popmap that I used from STACKS, note that I turned it from a tab separated headerless file 
# to a comma separated file with headers "id" and "pop" and put it in the "CARC-output" folder
popmap<-read.csv("CARC-output/sacer63.csv")
```

## Filtering Sacer 63 

```{r}
# Sacer 63 has all the samples. 

# So let's play with filtering!
hard_filter(vcfR=vcfR)

#hard filter to minimum depth of 5, and minimum genotype quality of 30
vcfR<-hard_filter(vcfR=vcfR, depth = 5, gq = 30)

```

## Allele balance 

```{r}
#From the SNP filtering tutorial:
# “Allele balance: a number between 0 and 1 representing the ratio of reads showing the 
# reference allele to all reads, considering only reads from individuals called as 
# heterozygous, we expect that the allele balance in our data (for real loci) should
#  be close to 0.5”

#the SNPfiltR allele balance function will convert heterozygous genotypes to 
# missing if they fall outside of the .25-.75 range.
#execute allele balance filter
vcfR<-filter_allele_balance(vcfR)

```

## Removing low quality samples  

```{r}
#visualize and pick appropriate max depth cutoff
# Now we can execute a max depth filter (super high depth loci are likely multiple loci 
# stuck together into a single paralogous locus).This filter is applied ‘per SNP’ rather 
# than ‘per genotype’ otherwise we would simply be removing most of the genotypes from 
# our deepest sequenced samples (because sequencing depth is so variable between samples).
# By filtering per SNP, we remove the SNPs with outlier depth values, which are most 
#likely to be spuriously mapped/built paralagous loci.

max_depth(vcfR)

# filter vcf by the max depth cutoff you chose
vcfR<-max_depth(vcfR, maxdepth = 157)

#check vcfR to see how many SNPs we have left
vcfR

#Set arbitrary cutoff for missing data allowed per sample. 
#We will start by determining which samples contain too few sequences to be used
# in downstream analyses, by visualizing missing data per sample
#run function to visualize samples
missing_by_sample(vcfR=vcfR, popmap = popmap)

#run function to drop samples above the threshold we want from the vcf
vcfR<-missing_by_sample(vcfR=vcfR, cutoff = .6)

#subset popmap to only include retained individuals
popmap<-popmap[popmap$id %in% colnames(vcfR@gt),]

```

## dealing with missing data

```{r}
#remove invariant sites generated by dropping individuals
vcfR<-min_mac(vcfR, min.mac = 1)

#verify that missing data is not driving clustering patterns among the retained samples
miss<-assess_missing_data_pca(vcfR=vcfR, popmap = popmap, thresholds = .8, clustering = FALSE)

#Set arbitrary cutoff for missing data allowed per SNP. 
#We can visualize the effect that typical missing data cutoffs will have on both
# the number of SNPs retained and the total missing data in our entire dataset.We
#want to choose a cutoff that minimizes the overall missing data in the dataset, 
#while maximizing the total number of loci retained.

#visualize missing data by SNP and the effect of various cutoffs on the missingnessof each sample
missing_by_snp(vcfR)

#verify that missing data is not driving clustering patterns among the retained samples at some reasonable thresholds
miss<-assess_missing_data_pca(vcfR=vcfR, popmap = popmap, thresholds = c(.7,.8,.85), clustering = FALSE)

miss<-assess_missing_data_pca(vcfR=vcfR, popmap = popmap, thresholds = c(.9,.95, 1.0), clustering = FALSE)

#choose a value that retains an acceptable amount of missing data in each sample, and maximizes SNPs retained while minimizing overall missing data, and filter vcf
vcfR<-missing_by_snp(vcfR, cutoff = .95)

#check how many SNPs and samples are left
vcfR


#
```

## investigate the effect of a minor allele count (MAC) cutoff on downstream inferences.

```{r}
#MAC/MAF cutoffs can be helpful in removing spurious and uninformative loci from
#the dataset, but also have the potential to bias downstream inferences. Linck 
#and Battey (2019) have an excellent paper on just this topic. 
  
#Our package contains a convenient wrapper functions that can filter based on 
#minor allele count (MAC) and streamline investigation of the effects of various
#filtering parameters on sample clustering patterns.

#investigate clustering patterns with and without a minor allele cutoff
#use min.mac() to investigate the effect of multiple cutoffs
vcfR.mac<-min_mac(vcfR = vcfR, min.mac = 2)

#assess clustering without MAC cutoff
miss<-assess_missing_data_tsne(vcfR, popmap, clustering = FALSE)

#assess clustering with MAC cutoff
miss<-assess_missing_data_tsne(vcfR.mac, popmap, clustering = FALSE)

#based on these visualizations, singletons are not obviously biasing clustering
# patterns, so I will leave them in for now. If I want to run a program like 
# STRUCTURE, where singletons are known to bias inference, I can write out the 
#vcf with singletons removed as well:
#vcfR::write.vcf(vcfR.mac, file = "output/sacer-no-singletons.146.vcf.gz")


```


## Quality per SNP and sample

```{r}
# Finally, we will make sure that the depth and genotype quality look consistent
# across SNPs and samples, following our filtering pipeline.
#plot depth per snp and per sample
dp <- extract.gt(vcfR, element = "DP", as.numeric=TRUE)
heatmap.bp(dp, rlabels = FALSE)

#plot genotype quality per snp and per sample
gq <- extract.gt(vcfR, element = "GQ", as.numeric=TRUE)
heatmap.bp(gq, rlabels = FALSE)

```


## Write out vcf files for downstream analyses

```{r}

# We can use the distance_thin() function from the SNPfiltR package
# in order to filter our SNPs to a minimum distance between SNPs, in order to 
# get a set of unlinked SNPs for downsteam analyses. 

#1. ALL SNPS
#write out vcf with all SNPs (uncomment when ready)
#vcfR::write.vcf(vcfR, "SNPfiltR-output/sacer.63.all_filtered.vcf.gz")
#vcfR

#2. UNLINKED SNPS
# write out a vcf file with thinned SNPs, here one per 500 bp
vcfR.thin<-distance_thin(vcfR, min.distance = 500)
vcfR.thin
#write out thinned vcf, uncomment when ready. 
#vcfR::write.vcf(vcfR.thin, "SNPfiltR-output/sacer.63.filtered.thinned.vcf.gz")

#3. ALL SNPS, NO SINGLETONS (for structure/smnf plots)
# Since singletons are known to bias inference with structure like lots, I will 
# produce a dataset with no singletons. 
vcfR.mac
#vcfR::write.vcf(vcfR.mac, file = "SNPfiltR-output/sacer.63.no-singletons.vcf.gz")

```

## getting a white list for downstream phylogenetic analyses 

```{r}
# if i wanted to start here later, i could download my filtered and thinned 
# vcf file like below. Otherwise, i could just use the "vcfR.thin" instead. Up to you. 

#vcfR_final<-read.vcfR("SNPfiltR-output/sacer.63.filtered.thinned.vcf.gz")
#vcfR_final
#
##check out the metadata
#head(vcfR_final@fix)
#
##we want to isolate the third column, which contains the name of each locus
#head(vcfR_final@fix[,3])
#
##get a list of just locus names to use as whitelist for stacks
#whitelist<-sub(":.*", "", vcfR_final@fix[,3])
#
##make sure each locus is unique
#length(unique(whitelist)) == length(whitelist)
#
##make sure the locus names look right
#whitelist[1:5]
#View(whitelist)
#
##write out whitelist for stacks
#write.table(whitelist, file = "SNPfiltR-output/sacer63_filteredSNPs.whitelist.txt", quote = F, row.names = F, col.names = F)
#
##generate popmap including only the samples in this  vcf file 
#df<-data.frame(ind=colnames(vcfR_final@gt)[-1], pop=gsub("_.*","", x=gsub("T_","",x = colnames(vcfR_final@gt)[-1])))
#
##write out popmap for stacks
#
#write.table(df, file = "SNPfiltR-output/sacer63_filteredSNPs.popmap.txt", quote = F, row.names = F, col.names = F, sep = "\t")
#
# in the same way you ran populations originally (from step #2), run this code instead (with no #)
#populations -P $src/populations_out/sacer63 -M $src/popmaps/sacer63.txt -O $src/populations_out/pop_sacer63_50per --whitelist popmaps/sacer63_filteredSNPs.whitelist.txt --phylip-var-all -t 8

```
